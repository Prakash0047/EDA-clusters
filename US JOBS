#Importing Libraries
import numpy as np
import pandas as pd

#Library for plots
import matplotlib.pyplot as plt
from plotly.offline import iplot, init_notebook_mode
init_notebook_mode()
import plotly.graph_objs as go

#Dataset import
org_data=pd.read_csv('Job Final Cleaned.csv')

#Interacting with dataset
org_data.head()
org_data.shape

#Copying the dataset
cln_data=org_data

#Cleaning Dataset
cln_data.isnull().sum()
cln_data=cln_data.dropna()
cln_data.head()
cln_data.shape

#Corelation with the data
corr=cln_data.corr()

#Visualization of the corelation through Seaborn
import seaborn as sns
sns.heatmap(corr, annot=True, linewidths=.5)

#Value count of Salary Periodicity
cln_data['salary_periodicity'].value_counts()

#setting catogarical value into
cln_data['salary_periodicity']=cln_data['salary_periodicity'].map({'yearly':0, 'hourly':1, 'weekly':2, 'monthly':3, 'daily':4}).astype(int)
cln_data['salary_periodicity'].median()

#boxplot with dynamic plot-PLOTLY for orginal dataset, to find the outliers
trace=[]
vals=[org_data['Salary  range end'], org_data['Salary range start']]
groups=["Salary  range end", "Salary range start"]
for i in range(0, len(groups)):
    trace.append(go.Box(y=vals[i],
                       name=groups[i]))
data2=trace
iplot({"data":data2})
    
    

#boxplot with dynamic plot-PLOTLY for cleaned dataset, to find the outliers    
trace=[]
vals=[cln_data['Salary  range end'], cln_data['Salary range start']]
groups=["Salary  range end", "Salary range start"]
for i in range(0, len(groups)):
    trace.append(go.Box(y=vals[i],
                       name=groups[i]))
data3=trace
iplot({"data":data3})  

#scatter plot of two main value
plt.scatter(x=cln_data['Salary  range end'],y=cln_data['Salary range start'])
plt.show()

#distribution visualization
sns.distplot(cln_data['Salary range start'], bins=20)
sns.distplot(cln_data['Salary  range end'])

#subset for the clusters
cluster=cln_data[['Salary  range end','Salary range start',]]
cluster.head()

#Feature scaling to establish mean and std. devation
from sklearn.preprocessing import StandardScaler
sc= StandardScaler()
data_F= sc.fit_transform(cluster)

#Elbow method for searching number of clusters in KMeans algorithm
from sklearn.cluster import KMeans
wcss=[]
for i in range(1,20):
    kmeans=KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(data_F)
    wcss.append(kmeans.inertia_)
plt.plot(range(1,20), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

#fitting the KMeans to the dataset
kmeans=KMeans(n_clusters=6,init='k-means++',random_state=42)
y_kmeans=kmeans.fit_predict(data_F) 


#visualizing the clusters
plt.scatter(data_F[y_kmeans==0,0], data_F[y_kmeans==0,1],s = 20,c = 'red',label='cluster 1')
plt.scatter(data_F[y_kmeans==1,0], data_F[y_kmeans==1,1],s=20,c='blue',label='Cluster 2')
plt.scatter(data_F[y_kmeans==2,0], data_F[y_kmeans==2,1], s=20,c='green',label='Cluster 3')
plt.scatter(data_F[y_kmeans==3,0], data_F[y_kmeans==3,1], s=20,c='magenta',label='Cluster 4')
plt.scatter(data_F[y_kmeans==4,0], data_F[y_kmeans==4,1], s=20,c='brown',label='Cluster 5')
plt.scatter(data_F[y_kmeans==5,0], data_F[y_kmeans==5,1], s=20,c='yellow',label='Cluster 5')
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=50,c='black',label='Centroids',alpha=1.0)
plt.xlabel
plt.legend()
plt.show()
